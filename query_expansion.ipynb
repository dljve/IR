{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Question</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>156493</td>\n",
       "      <td>do goldfish grow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1110199</td>\n",
       "      <td>what is wifi vs bluetooth</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1063750</td>\n",
       "      <td>why did the us volunterilay enter ww1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>130510</td>\n",
       "      <td>definition declaratory judgment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>489204</td>\n",
       "      <td>right pelvic pain causes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        ID                               Question\n",
       "0   156493                       do goldfish grow\n",
       "1  1110199              what is wifi vs bluetooth\n",
       "2  1063750  why did the us volunterilay enter ww1\n",
       "3   130510        definition declaratory judgment\n",
       "4   489204               right pelvic pain causes"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "#path = \"G:/python/anserini/src/main/resources/topics-and-qrels/\"\n",
    "path = \"C:/Users/Thijs-Jan-Luttikholt/Documents/Study/Master/Year 1/Information retrieval/anserini/src/main/resources/topics-and-qrels/\"\n",
    "topics_file = \"topics.dl19-doc.txt\"\n",
    "\n",
    "topics = pd.read_csv(path+topics_file,sep=\"\\t\",names=[\"ID\",\"Question\"])\n",
    "topics[\"ID\"]= topics[\"ID\"].astype(str)\n",
    "\n",
    "topics.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiments\n",
    "Results file format from: http://www.rafaelglater.com/en/post/learn-how-to-use-trec_eval-to-evaluate-your-information-retrieval-system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyserini.search import SimpleSearcher\n",
    "\n",
    "#searcher = SimpleSearcher('G:/python/anserini/lucene-index.robust04.pos+docvectors+rawdocs')\n",
    "#searcher = SimpleSearcher('C:/msmarco-doc/lucene-index.msmarco-doc.pos+docvectors+rawdocs')\n",
    "searcher = SimpleSearcher('C:/Users/Thijs-Jan-Luttikholt/Documents/Study/Master/Year 1/Information retrieval/Project/lucene-index.msmarco-doc.pos+docvectors+rawdocs/lucene-index.msmarco-doc.pos+docvectors+rawdocs')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BM25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "searcher.set_bm25(0.9, 0.4)\n",
    "\n",
    "f = open(\"runs/bm25.txt\", \"w\") \n",
    "for (topicid,question) in zip(topics[\"ID\"], topics[\"Question\"]):\n",
    "    hits = searcher.search(question)\n",
    "    for i in range(0, 10):\n",
    "        f.write(f'{topicid}\\tQ0\\t{hits[i].docid}\\t{i+1:2}\\t{hits[i].score:.5f}\\tSTANDARD\\n')   \n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BM25+RM3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "searcher.set_bm25(0.9, 0.4)\n",
    "searcher.set_rm3(10, 10, 0.5,rm3_output_query=True)\n",
    "\n",
    "f = open(\"runs/bm25+rm3.txt\", \"w\") \n",
    "for (topicid,question) in zip(topics[\"ID\"], topics[\"Question\"]):\n",
    "    hits = searcher.search(question)\n",
    "    for i in range(0, 10):\n",
    "        f.write(f'{topicid}\\tQ0\\t{hits[i].docid}\\t{i+1:2}\\t{hits[i].score:.5f}\\tSTANDARD\\n')\n",
    "f.close()\n",
    "\n",
    "searcher.unset_rm3()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word2Vec QE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'spacy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-53-c9346a4521b9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mgensim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mWord2Vec\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mgensim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdownloader\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mapi\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mspacy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mpyserini\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0manalysis\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mAnalyzer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mget_lucene_analyzer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'spacy'"
     ]
    }
   ],
   "source": [
    "import gensim \n",
    "from gensim.models import Word2Vec\n",
    "import gensim.downloader as api\n",
    "import spacy\n",
    "from pyserini.analysis import Analyzer, get_lucene_analyzer\n",
    "\n",
    "path = \"G:/data/glove.6B.300d.w2v.txt\"\n",
    "model = gensim.models.KeyedVectors.load_word2vec_format(path, binary = False)\n",
    "word_vectors = model.wv\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "analyzer = Analyzer(get_lucene_analyzer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'do goldfish grow' expansions:\n",
      "    goldfish -> koi\n",
      "    grow -> growth\n",
      "\n",
      "\n",
      "'what is wifi vs bluetooth' expansions:\n",
      "    wifi -> wi-fi\n",
      "    vs -> vs.\n",
      "    bluetooth -> wifi\n",
      "\n",
      "\n",
      "'why did the us volunterilay enter ww1' expansions:\n",
      "    enter -> entry\n",
      "    ww1 -> ww2\n",
      "\n",
      "\n",
      "'definition declaratory judgment' expansions:\n",
      "    definition -> defined\n",
      "    declaratory -> injunctive\n",
      "    judgment -> judgement\n",
      "\n",
      "\n",
      "'right pelvic pain causes' expansions:\n",
      "    right -> left\n",
      "    pelvic -> abdominal\n",
      "    pain -> discomfort\n",
      "    causes -> disease\n",
      "\n",
      "\n",
      "'what are the social determinants of health' expansions:\n",
      "    social -> welfare\n",
      "    determinants -> predictors\n",
      "    health -> care\n",
      "\n",
      "\n",
      "'how is the weather in jamaica' expansions:\n",
      "    weather -> inclement\n",
      "    jamaica -> barbados\n",
      "\n",
      "\n",
      "'types of dysarthria from cerebral palsy' expansions:\n",
      "    types -> kinds\n",
      "    dysarthria -> ataxic\n",
      "    cerebral -> palsy\n",
      "    palsy -> cerebral\n",
      "\n",
      "\n",
      "'who is robert gray' expansions:\n",
      "    robert -> william\n",
      "    gray -> grey\n",
      "\n",
      "\n",
      "'what types of food can you cook sous vide' expansions:\n",
      "    types -> kinds\n",
      "    food -> foods\n",
      "    cook -> fry\n",
      "    sous -> clichy\n",
      "    vide -> sous\n",
      "\n",
      "\n",
      "'how long is life cycle of flea' expansions:\n",
      "    long -> short\n",
      "    life -> years\n",
      "    cycle -> beginning\n",
      "    flea -> fleas\n",
      "\n",
      "\n",
      "'what can contour plowing reduce' expansions:\n",
      "    contour -> contours\n",
      "    plowing -> ploughing\n",
      "    reduce -> increase\n",
      "\n",
      "\n",
      "'when was the salvation army founded' expansions:\n",
      "    salvation -> redemption\n",
      "    army -> military\n",
      "    founded -> established\n",
      "\n",
      "\n",
      "'what is a active margin' expansions:\n",
      "    active -> actively\n",
      "    margin -> percentage\n",
      "\n",
      "\n",
      "'difference between rn and bsn' expansions:\n",
      "    difference -> fact\n",
      "    rn -> clr\n",
      "    bsn -> simpanan\n",
      "\n",
      "\n",
      "'medicare's definition of mechanical ventilation' expansions:\n",
      "    definition -> defined\n",
      "    mechanical -> electrical\n",
      "    ventilation -> hvac\n",
      "\n",
      "\n",
      "'how to find the midsegment of a trapezoid' expansions:\n",
      "    find -> able\n",
      "    trapezoid -> trapezoidal\n",
      "\n",
      "\n",
      "'what is an aml surveillance analyst' expansions:\n",
      "    aml -> myeloid\n",
      "    surveillance -> monitoring\n",
      "    analyst -> lynch\n",
      "\n",
      "\n",
      "'what is the daily life of thai people' expansions:\n",
      "    daily -> newspaper\n",
      "    life -> years\n",
      "    thai -> thailand\n",
      "    people -> others\n",
      "\n",
      "\n",
      "'definition of a sigmet' expansions:\n",
      "    definition -> defined\n",
      "\n",
      "\n",
      "'cost of interior concrete flooring' expansions:\n",
      "    cost -> pay\n",
      "    interior -> ministry\n",
      "    concrete -> walls\n",
      "    flooring -> laminate\n",
      "\n",
      "\n",
      "'what is the most popular food in switzerland' expansions:\n",
      "    popular -> popularity\n",
      "    food -> foods\n",
      "    switzerland -> swiss\n",
      "\n",
      "\n",
      "'how are some sharks warm blooded' expansions:\n",
      "    sharks -> shark\n",
      "    warm -> cool\n",
      "    blooded -> cold-blooded\n",
      "\n",
      "\n",
      "'how long to hold bow in yoga' expansions:\n",
      "    long -> short\n",
      "    hold -> take\n",
      "    bow -> jhaw\n",
      "    yoga -> meditation\n",
      "\n",
      "\n",
      "'what is durable medical equipment consist of' expansions:\n",
      "    durable -> goods\n",
      "    medical -> hospital\n",
      "    equipment -> machinery\n",
      "    consist -> comprise\n",
      "\n",
      "\n",
      "'exons definition biology' expansions:\n",
      "    exons -> introns\n",
      "    definition -> defined\n",
      "    biology -> biochemistry\n",
      "\n",
      "\n",
      "'define visceral?' expansions:\n",
      "    define -> redefine\n",
      "\n",
      "\n",
      "'tracheids are part of _____.' expansions:\n",
      "    tracheids -> xerophytic\n",
      "\n",
      "\n",
      "'how many liberty ships were built in brunswick' expansions:\n",
      "    liberty -> freedom\n",
      "    ships -> vessels\n",
      "    built -> constructed\n",
      "    brunswick -> scotia\n",
      "\n",
      "\n",
      "'rsa definition key' expansions:\n",
      "    rsa -> aus\n",
      "    definition -> defined\n",
      "    key -> crucial\n",
      "\n",
      "\n",
      "'who formed the commonwealth of independent states' expansions:\n",
      "    formed -> formation\n",
      "    commonwealth -> polish-lithuanian\n",
      "    independent -> independence\n",
      "    states -> united\n",
      "\n",
      "\n",
      "'causes of left ventricular hypertrophy' expansions:\n",
      "    causes -> disease\n",
      "    left -> leaving\n",
      "    ventricular -> atrial\n",
      "    hypertrophy -> ventricular\n",
      "\n",
      "\n",
      "'lps laws definition' expansions:\n",
      "    lps -> 45s\n",
      "    laws -> regulations\n",
      "    definition -> defined\n",
      "\n",
      "\n",
      "'causes of military suicide' expansions:\n",
      "    causes -> disease\n",
      "    military -> army\n",
      "    suicide -> bombings\n",
      "\n",
      "\n",
      "'what is theraderm used for' expansions:\n",
      "\n",
      "\n",
      "'what is famvir prescribed for' expansions:\n",
      "    famvir -> valtrex\n",
      "    prescribed -> medication\n",
      "\n",
      "\n",
      "'anthropological definition of environment' expansions:\n",
      "    anthropological -> ethnological\n",
      "    definition -> defined\n",
      "    environment -> environmental\n",
      "\n",
      "\n",
      "'axon terminals or synaptic knob definition' expansions:\n",
      "    axon -> axonal\n",
      "    terminals -> ports\n",
      "    synaptic -> plasticity\n",
      "    knob -> knobs\n",
      "    definition -> defined\n",
      "\n",
      "\n",
      "'is cdg airport in main paris' expansions:\n",
      "    cdg -> -8.00\n",
      "    airport -> flights\n",
      "    main -> key\n",
      "    paris -> prohertrib\n",
      "\n",
      "\n",
      "'example of monotonic function' expansions:\n",
      "    example -> instance\n",
      "    monotonic -> real-valued\n",
      "    function -> i.e.\n",
      "\n",
      "\n",
      "'what is physical description of spruce' expansions:\n",
      "    physical -> mental\n",
      "    description -> describing\n",
      "    spruce -> fir\n",
      "\n",
      "\n",
      "'hydrogen is a liquid below what temperature' expansions:\n",
      "    hydrogen -> helium\n",
      "    liquid -> mixture\n",
      "    temperature -> humidity\n",
      "\n",
      "\n",
      "'difference between a mcdouble and a double cheeseburger' expansions:\n",
      "    difference -> fact\n",
      "    double -> triple\n",
      "    cheeseburger -> fries\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyserini.search import querybuilder as qb\n",
    "\n",
    "f = open(\"runs/word2vec.txt\", \"w\") \n",
    "for (topicid,question) in zip(topics[\"ID\"], topics[\"Question\"]):\n",
    "    # Build the query\n",
    "    builder = qb.get_boolean_query_builder()\n",
    "    should = qb.JBooleanClauseOccur['should'].value # should occur\n",
    "    print(\"'\"+question+\"' expansions:\")\n",
    "    for token in question.split(\" \"):\n",
    "        if len(analyzer.analyze(token))>0:\n",
    "            # add question token\n",
    "            builder.add(qb.get_boost_query(qb.get_term_query(token), 1),should)\n",
    "            \n",
    "            # word2vec expansion\n",
    "            if token in word_vectors.vocab and not token in nlp.Defaults.stop_words:\n",
    "                token_lemma = nlp(token)[0].lemma_\n",
    "                syns = model.most_similar(token)\n",
    "                synonyms = [syn for (syn,score) in syns if nlp(syn)[0].lemma_ != token_lemma][:1]\n",
    "                for synonym in synonyms:\n",
    "                    if len(analyzer.analyze(synonym))>0:\n",
    "                        # add query term\n",
    "                        builder.add(qb.get_boost_query(qb.get_term_query(token), 0.1),should)\n",
    "                        print(\"    \"+token+\" -> \"+synonym)\n",
    "            \n",
    "    question = builder.build()\n",
    "    print(\"\\n\")\n",
    "\n",
    "    hits = searcher.search(question)\n",
    "    for i in range(0, 10):\n",
    "        f.write(f'{topicid}\\tQ0\\t{hits[i].docid}\\t{i+1:2}\\t{hits[i].score:.5f}\\tSTANDARD\\n')\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wordnet QE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import wordnet as wn \n",
    "from nltk.tokenize import sent_tokenize, word_tokenize \n",
    "import warnings \n",
    "from nltk.corpus import words\n",
    "from operator import itemgetter\n",
    "from pyserini.search import querybuilder as qb\n",
    "from pyserini.analysis import Analyzer, get_lucene_analyzer\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package words to C:\\Users\\Thijs-Jan-\n",
      "[nltk_data]     Luttikholt\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\words.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('words')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The following function creates a set containing synonyms for each word in the input list.\n",
    "def add_synonyms(myList):\n",
    "    synonyms = []\n",
    "    for word in myList:\n",
    "        for syn in wn.synsets(word):\n",
    "            for l in syn.lemmas():\n",
    "                synonyms.append(l.name())\n",
    "    return set(synonyms)\n",
    "\n",
    "#The following function creates a set containing hypernyms for each word in the input list.\n",
    "def add_hypernyms(myList):\n",
    "    hypernyms = []\n",
    "    for word in myList:\n",
    "        for syn in wn.synsets(word):\n",
    "            for h in syn.hypernyms():\n",
    "                #hypernyms.append(h.name().split('.')[0])\n",
    "                hypernyms.append(h.name())\n",
    "    return set(hypernyms)\n",
    "\n",
    "#The following function creates a set containing hyponyms for each word in the input list.\n",
    "def add_hyponyms(myList):\n",
    "    hyponyms = []\n",
    "    for word in myList:\n",
    "        for syn in wn.synsets(word):\n",
    "            for h in syn.hyponyms():\n",
    "                hyponyms.append(h.name().split('.')[0])\n",
    "    return set(hyponyms)\n",
    "\n",
    "#The following function creates a set containing meronyms for each word in the input list.\n",
    "def add_meronyms(myList):\n",
    "    meronyms = []\n",
    "    for word in myList:\n",
    "        for syn in wn.synsets(word):\n",
    "            for m in syn.part_meronyms():\n",
    "                meronyms.append(m.name().split('.')[0])\n",
    "    return set(meronyms)\n",
    "\n",
    "#The following function creates a set containing holonyms for each word in the input list.\n",
    "def add_holonyms(myList):\n",
    "    holonyms = []\n",
    "    for word in myList:\n",
    "        for syn in wn.synsets(word):\n",
    "            for m in syn.part_holonyms():\n",
    "                holonyms.append(m.name().split('.')[0])\n",
    "    return set(holonyms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['hound']\n"
     ]
    }
   ],
   "source": [
    "def best_synonyms(original, synonyms, max_len, min_sim):\n",
    "    syns_scores = []\n",
    "    orig_set = wn.synsets(original)[0]\n",
    "    set_type = orig_set.name().split('.')[1]\n",
    "    \n",
    "    i = 1\n",
    "    for word in synonyms:\n",
    "        word_sets = wn.synsets(word)\n",
    "        word_set = None\n",
    "        for item in word_sets:\n",
    "            if item.name().split('.')[1] is set_type:\n",
    "                word_set = item\n",
    "                break\n",
    "        if word_set is None:\n",
    "            continue\n",
    "        score = orig_set.path_similarity(word_set) \n",
    "        if score is None:\n",
    "            continue\n",
    "        if score >= min_sim:\n",
    "            if len(syns_scores) < max_len:\n",
    "                syns_scores.append([word,score])\n",
    "            elif len(syns_scores) == max_len and score > syns_scores[max_len-1][1]:\n",
    "                syns_scores[max_len-1] = [word,score]\n",
    "            syns_scores = sorted(syns_scores, key=itemgetter(1))\n",
    "    final_syns = [word for word,score in syns_scores if word != original]\n",
    "    return final_syns\n",
    "\n",
    "def filter_words(myList):\n",
    "    new_list = []\n",
    "    for item in myList:\n",
    "        if '_' not in item:\n",
    "            new_list.append(item)\n",
    "    return new_list\n",
    "\n",
    "\n",
    "best_syns = best_synonyms('dog', add_synonyms(['dog']), 100, 0.2)\n",
    "print(filter_words(best_syns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzer = Analyzer(get_lucene_analyzer())\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'do goldfish grow' expansions:\n",
      "    grow -> originate\n",
      "    grow -> uprise\n",
      "\n",
      "\n",
      "'what is wifi vs bluetooth' expansions:\n",
      "\n",
      "\n",
      "'why did the us volunterilay enter ww1' expansions:\n",
      "    enter -> figure\n",
      "\n",
      "\n",
      "'definition declaratory judgment' expansions:\n",
      "    declaratory -> declarative\n",
      "    declaratory -> asserting\n",
      "    judgment -> opinion\n",
      "\n",
      "\n",
      "'right pelvic pain causes' expansions:\n",
      "    pain -> hurting\n",
      "\n",
      "\n",
      "'what are the social determinants of health' expansions:\n",
      "    social -> sociable\n",
      "    social -> mixer\n",
      "    health -> wellness\n",
      "\n",
      "\n",
      "'how is the weather in jamaica' expansions:\n",
      "\n",
      "\n",
      "'types of dysarthria from cerebral palsy' expansions:\n",
      "    palsy -> paralysis\n",
      "\n",
      "\n",
      "'who is robert gray' expansions:\n",
      "    gray -> grayness\n",
      "    gray -> Gray\n",
      "\n",
      "\n",
      "'what types of food can you cook sous vide' expansions:\n",
      "    food -> nutrient\n",
      "    cook -> Cook\n",
      "\n",
      "\n",
      "'how long is life cycle of flea' expansions:\n",
      "    long -> hanker\n",
      "    long -> yearn\n",
      "    life -> aliveness\n",
      "    life -> animation\n",
      "\n",
      "\n",
      "'what can contour plowing reduce' expansions:\n",
      "    plowing -> ploughing\n",
      "    reduce -> dilute\n",
      "    reduce -> foreshorten\n",
      "\n",
      "\n",
      "'when was the salvation army founded' expansions:\n",
      "    salvation -> redemption\n",
      "\n",
      "\n",
      "'what is a active margin' expansions:\n",
      "    margin -> perimeter\n",
      "\n",
      "\n",
      "'difference between rn and bsn' expansions:\n",
      "\n",
      "\n",
      "'medicare's definition of mechanical ventilation' expansions:\n",
      "\n",
      "\n",
      "'how to find the midsegment of a trapezoid' expansions:\n",
      "    find -> breakthrough\n",
      "\n",
      "\n",
      "'what is an aml surveillance analyst' expansions:\n",
      "\n",
      "\n",
      "'what is the daily life of thai people' expansions:\n",
      "    life -> aliveness\n",
      "    life -> animation\n",
      "    people -> masses\n",
      "\n",
      "\n",
      "'definition of a sigmet' expansions:\n",
      "\n",
      "\n",
      "'cost of interior concrete flooring' expansions:\n",
      "    cost -> toll\n",
      "    interior -> inside\n",
      "    interior -> Interior\n",
      "    flooring -> deck\n",
      "    flooring -> floor\n",
      "\n",
      "\n",
      "'what is the most popular food in switzerland' expansions:\n",
      "    food -> nutrient\n",
      "\n",
      "\n",
      "'how are some sharks warm blooded' expansions:\n",
      "    warm -> tender\n",
      "    blooded -> blood\n",
      "\n",
      "\n",
      "'how long to hold bow in yoga' expansions:\n",
      "    long -> hanker\n",
      "    long -> yearn\n",
      "    hold -> support\n",
      "    hold -> grip\n",
      "    bow -> bowknot\n",
      "\n",
      "\n",
      "'what is durable medical equipment consist of' expansions:\n",
      "    durable -> long-lived\n",
      "    durable -> long-lasting\n",
      "    consist -> comprise\n",
      "\n",
      "\n",
      "'exons definition biology' expansions:\n",
      "\n",
      "\n",
      "'define visceral?' expansions:\n",
      "    define -> delineate\n",
      "    define -> delimit\n",
      "\n",
      "\n",
      "'tracheids are part of _____.' expansions:\n",
      "\n",
      "\n",
      "'how many liberty ships were built in brunswick' expansions:\n",
      "    liberty -> autonomy\n",
      "    built -> establish\n",
      "    built -> build\n",
      "    brunswick -> Braunschweig\n",
      "    brunswick -> Brunswick\n",
      "\n",
      "\n",
      "'rsa definition key' expansions:\n",
      "    key -> Key\n",
      "\n",
      "\n",
      "'who formed the commonwealth of independent states' expansions:\n",
      "    formed -> mold\n",
      "    formed -> constitute\n",
      "    commonwealth -> state\n",
      "    independent -> sovereign\n",
      "    independent -> fencesitter\n",
      "\n",
      "\n",
      "'causes of left ventricular hypertrophy' expansions:\n",
      "\n",
      "\n",
      "'lps laws definition' expansions:\n",
      "\n",
      "\n",
      "'causes of military suicide' expansions:\n",
      "    suicide -> self-destruction\n",
      "    suicide -> self-annihilation\n",
      "\n",
      "\n",
      "'what is theraderm used for' expansions:\n",
      "\n",
      "\n",
      "'what is famvir prescribed for' expansions:\n",
      "\n",
      "\n",
      "'anthropological definition of environment' expansions:\n",
      "    environment -> surroundings\n",
      "\n",
      "\n",
      "'axon terminals or synaptic knob definition' expansions:\n",
      "    axon -> axone\n",
      "\n",
      "\n",
      "'is cdg airport in main paris' expansions:\n",
      "    airport -> aerodrome\n",
      "    airport -> drome\n",
      "    main -> briny\n",
      "\n",
      "\n",
      "'example of monotonic function' expansions:\n",
      "    monotonic -> monotone\n",
      "    function -> mapping\n",
      "\n",
      "\n",
      "'what is physical description of spruce' expansions:\n",
      "\n",
      "\n",
      "'hydrogen is a liquid below what temperature' expansions:\n",
      "    hydrogen -> H\n",
      "    liquid -> fluid\n",
      "\n",
      "\n",
      "'difference between a mcdouble and a double cheeseburger' expansions:\n",
      "    double -> two-bagger\n",
      "    double -> two-baser\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "f = open(\"runs/wordnet.txt\", \"w\") \n",
    "for (topicid,question) in zip(topics[\"ID\"], topics[\"Question\"]):\n",
    "    # Build the query\n",
    "    builder = qb.get_boolean_query_builder()\n",
    "    should = qb.JBooleanClauseOccur['should'].value # should occur\n",
    "    print(\"'\"+question+\"' expansions:\")\n",
    "    for token in question.split(\" \"):\n",
    "        if len(analyzer.analyze(token))>0:\n",
    "            # add question token\n",
    "            builder.add(qb.get_boost_query(qb.get_term_query(token), 1),should)\n",
    "            \n",
    "            # wordnet expansion\n",
    "            if token not in nlp.Defaults.stop_words and token in words.words():\n",
    "                token_lemma = nlp(token)[0].lemma_\n",
    "                \n",
    "                wordnet_synonyms = add_synonyms([token])\n",
    "                synonyms = best_synonyms(token, wordnet_synonyms, 3, 0.2)\n",
    "                synonyms = filter_words(synonyms)\n",
    "                for synonym in synonyms:\n",
    "                    if len(analyzer.analyze(synonym))>0:\n",
    "                        # add query term\n",
    "                        builder.add(qb.get_boost_query(qb.get_term_query(token), 0.1),should)\n",
    "                        print(\"    \"+token+\" -> \"+synonym)\n",
    "            \n",
    "    question = builder.build()\n",
    "    print(\"\\n\")\n",
    "\n",
    "    hits = searcher.search(question)\n",
    "    for i in range(0, 10):\n",
    "        f.write(f'{topicid}\\tQ0\\t{hits[i].docid}\\t{i+1:2}\\t{hits[i].score:.5f}\\tSTANDARD\\n')\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
