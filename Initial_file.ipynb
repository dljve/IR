{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Information retrieval project:\n",
    "\n",
    "##### Group-N-13\n",
    "\n",
    "In this file, we will program the various necessary parts of our project. We will use markdown cells in between the code cells to elaborate on what each code cell contains. In addition to this, we will use comments in the code itself."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initial imports and downloads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import wordnet \n",
    "from nltk.tokenize import sent_tokenize, word_tokenize \n",
    "import warnings \n",
    "import gensim \n",
    "from gensim.models import Word2Vec "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to C:\\Users\\Thijs-Jan-\n",
      "[nltk_data]     Luttikholt\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#The following lines are only necessary if the corresponding data is not yet downloaded.\n",
    "#nltk.download('wordnet')\n",
    "#nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### wordnet-based semantically related words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'skillful', 'undecomposed', 'good', 'right', 'goodness', 'effective', 'ripe', 'thoroughly', 'in_effect', 'salutary', 'full', 'honest', 'dependable', 'respectable', 'secure', 'unspoiled', 'sound', 'trade_good', 'skilful', 'near', 'commodity', 'beneficial', 'unspoilt', 'safe', 'expert', 'dear', 'in_force', 'just', 'adept', 'well', 'serious', 'honorable', 'estimable', 'practiced', 'proficient', 'soundly', 'upright'}\n",
      "{'radical', 'chromatic_color', 'sum', 'red'}\n",
      "{'blush', 'redden', 'heather_mixture', 'coloration', 'turn', 'miniate', 'paint', 'blacken', 'tone', 'green', 'face_value', 'retouch', 'verisimilitude', 'mordant', 'motley', 'pigment', 'whiten', 'primary_color', 'aurify', 'indicator', 'tincture', 'silver', 'pale', 'disguise', 'yellow', 'tan', 'azure', 'color_of_law', 'purple', 'polychrome', 'color', 'verdigris', 'imbue', 'hematochrome', 'complexion', 'simulacrum', 'grey', 'guise', 'chromatic_color', 'embrown', 'stain', 'sunburn', 'handcolor', 'pinkify', 'tint', 'achromatic_color', 'blackwash', 'dye', 'mottle', 'blue', 'nonsolid_color', 'shade', 'incarnadine'}\n",
      "{'hand', 'palm', 'metacarpus', 'long_suit', 'digital_arteries', 'ball', 'intercapitular_vein', 'finger', 'metacarpal_artery', 'metacarpal_vein'}\n",
      "{'glove', 'hand', 'finger'}\n"
     ]
    }
   ],
   "source": [
    "#The following function creates a set containing synonyms for each word in the input list.\n",
    "def add_synonyms(myList):\n",
    "    synonyms = []\n",
    "    for word in myList:\n",
    "        for syn in wordnet.synsets(word):\n",
    "            for l in syn.lemmas():\n",
    "                synonyms.append(l.name())\n",
    "    myList.extend(synonyms)\n",
    "    return set(myList)\n",
    "\n",
    "#The following function creates a set containing hypernyms for each word in the input list.\n",
    "def add_hypernyms(myList):\n",
    "    hypernyms = []\n",
    "    for word in myList:\n",
    "        for syn in wordnet.synsets(word):\n",
    "            for h in syn.hypernyms():\n",
    "                hypernyms.append(h.name().split('.')[0])\n",
    "    myList.extend(hypernyms)\n",
    "    return set(myList)\n",
    "\n",
    "#The following function creates a set containing hyponyms for each word in the input list.\n",
    "def add_hyponyms(myList):\n",
    "    hyponyms = []\n",
    "    for word in myList:\n",
    "        for syn in wordnet.synsets(word):\n",
    "            for h in syn.hyponyms():\n",
    "                hyponyms.append(h.name().split('.')[0])\n",
    "    myList.extend(hyponyms)\n",
    "    return set(myList)\n",
    "\n",
    "#The following function creates a set containing meronyms for each word in the input list.\n",
    "def add_meronyms(myList):\n",
    "    meronyms = []\n",
    "    for word in myList:\n",
    "        for syn in wordnet.synsets(word):\n",
    "            for m in syn.part_meronyms():\n",
    "                meronyms.append(m.name().split('.')[0])\n",
    "    myList.extend(meronyms)\n",
    "    return set(myList)\n",
    "\n",
    "#The following function creates a set containing holonyms for each word in the input list.\n",
    "def add_holonyms(myList):\n",
    "    holonyms = []\n",
    "    for word in myList:\n",
    "        for syn in wordnet.synsets(word):\n",
    "            for m in syn.part_holonyms():\n",
    "                holonyms.append(m.name().split('.')[0])\n",
    "    myList.extend(holonyms)\n",
    "    return set(myList)\n",
    "\n",
    "print(add_synonyms([\"good\"]))    \n",
    "print(add_hypernyms([\"red\"]))\n",
    "print(add_hyponyms([\"color\"]))\n",
    "print(add_meronyms([\"hand\"]))\n",
    "print(add_holonyms([\"finger\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### word2vec initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(action = 'ignore') \n",
    "path = \"glove.6B.300d.w2v.txt\"\n",
    "word2vec = gensim.models.KeyedVectors.load_word2vec_format(path, binary = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('darker', 0.5255928635597229),\n",
       " ('pale', 0.5101213455200195),\n",
       " ('bright', 0.49969482421875),\n",
       " ('gray', 0.48213768005371094),\n",
       " ('light', 0.4572194814682007),\n",
       " ('shadows', 0.4532138705253601),\n",
       " ('blue', 0.4475400447845459),\n",
       " ('shades', 0.44578641653060913),\n",
       " ('house', 0.4422840178012848),\n",
       " ('red', 0.4410778284072876)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2vec.most_similar(positive=['paris','germany'], negative=['france'])\n",
    "word2vec.most_similar(positive=['branch','finger'], negative=['twig'])\n",
    "word2vec.most_similar(positive=['dark','white'], negative=['black'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
