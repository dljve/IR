{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to C:\\Users\\Thijs-Jan-\n",
      "[nltk_data]     Luttikholt\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\wordnet.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'glove', 'finger', 'hand'}\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import wordnet \n",
    "\n",
    "def add_synonyms(myList):\n",
    "    synonyms = []\n",
    "    for word in myList:\n",
    "        for syn in wordnet.synsets(word):\n",
    "            for l in syn.lemmas():\n",
    "                synonyms.append(l.name())\n",
    "    myList.extend(synonyms)\n",
    "    return set(myList)\n",
    "\n",
    "def add_hypernyms(myList):\n",
    "    hypernyms = []\n",
    "    for word in myList:\n",
    "        for syn in wordnet.synsets(word):\n",
    "            for h in syn.hypernyms():\n",
    "                hypernyms.append(h.name().split('.')[0])\n",
    "    myList.extend(hypernyms)\n",
    "    return set(myList)\n",
    "\n",
    "def add_hyponyms(myList):\n",
    "    hyponyms = []\n",
    "    for word in myList:\n",
    "        for syn in wordnet.synsets(word):\n",
    "            for h in syn.hyponyms():\n",
    "                hyponyms.append(h.name().split('.')[0])\n",
    "    myList.extend(hyponyms)\n",
    "    return set(myList)\n",
    "\n",
    "def add_meronyms(myList):\n",
    "    meronyms = []\n",
    "    for word in myList:\n",
    "        for syn in wordnet.synsets(word):\n",
    "            for m in syn.part_meronyms():\n",
    "                meronyms.append(m.name().split('.')[0])\n",
    "    myList.extend(meronyms)\n",
    "    return set(myList)\n",
    "\n",
    "def add_holonyms(myList):\n",
    "    holonyms = []\n",
    "    for word in myList:\n",
    "        for syn in wordnet.synsets(word):\n",
    "            for m in syn.part_holonyms():\n",
    "                holonyms.append(m.name().split('.')[0])\n",
    "    myList.extend(holonyms)\n",
    "    return set(myList)\n",
    "\n",
    "print(add_synonyms([\"good\"]))    \n",
    "print(add_hypernyms([\"red\"]))\n",
    "print(add_hyponyms([\"color\"]))\n",
    "print(add_meronyms([\"hand\"]))\n",
    "print(add_holonyms([\"finger\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize, word_tokenize \n",
    "import warnings \n",
    "#nltk.download('punkt')\n",
    "\n",
    "warnings.filterwarnings(action = 'ignore') \n",
    "  \n",
    "import gensim \n",
    "from gensim.models import Word2Vec "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"glove.6B.300d.w2v.txt\"\n",
    "word2vec = gensim.models.KeyedVectors.load_word2vec_format(path, binary = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('darker', 0.5255928635597229),\n",
       " ('pale', 0.5101213455200195),\n",
       " ('bright', 0.49969482421875),\n",
       " ('gray', 0.48213768005371094),\n",
       " ('light', 0.4572194814682007),\n",
       " ('shadows', 0.4532138705253601),\n",
       " ('blue', 0.4475400447845459),\n",
       " ('shades', 0.44578641653060913),\n",
       " ('house', 0.4422840178012848),\n",
       " ('red', 0.4410778284072876)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2vec.most_similar(positive=['paris','germany'], negative=['france'])\n",
    "word2vec.most_similar(positive=['branch','finger'], negative=['twig'])\n",
    "word2vec.most_similar(positive=['dark','white'], negative=['black'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('yellow', 0.6828818321228027),\n",
       " ('blue', 0.6736692786216736),\n",
       " ('pink', 0.5893942713737488),\n",
       " ('green', 0.5799195766448975),\n",
       " ('white', 0.5733829736709595),\n",
       " ('purple', 0.5530809760093689),\n",
       " ('black', 0.5441405177116394),\n",
       " ('colored', 0.5216450691223145),\n",
       " ('sox', 0.5209405422210693),\n",
       " ('bright', 0.5119451284408569)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2vec.most_similar('red')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
