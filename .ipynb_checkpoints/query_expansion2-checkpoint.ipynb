{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Question</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>174249</td>\n",
       "      <td>does xpress bet charge to deposit money in you...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>320792</td>\n",
       "      <td>how much is a cost to run disneyland</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1090270</td>\n",
       "      <td>botulinum definition</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1101279</td>\n",
       "      <td>do physicians pay for insurance from their sal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>201376</td>\n",
       "      <td>here there be dragons comic</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        ID                                           Question\n",
       "0   174249  does xpress bet charge to deposit money in you...\n",
       "1   320792               how much is a cost to run disneyland\n",
       "2  1090270                               botulinum definition\n",
       "3  1101279  do physicians pay for insurance from their sal...\n",
       "4   201376                        here there be dragons comic"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "#path = \"G:/python/anserini/src/main/resources/topics-and-qrels/\"\n",
    "#path = \"C:/Users/Thijs-Jan-Luttikholt/Documents/Study/Master/Year 1/Information retrieval/anserini/src/main/resources/topics-and-qrels/\"\n",
    "path = \"C:/Users/Loes/Documents/M1/IR/anserini/src/main/resources/topics-and-qrels/\"\n",
    "#topics_file = \"topics.dl19-doc.txt\"\n",
    "topics_file = \"topics.msmarco-doc.dev.txt\"\n",
    "\n",
    "topics = pd.read_csv(path+topics_file,sep=\"\\t\",names=[\"ID\",\"Question\"])\n",
    "topics[\"ID\"]= topics[\"ID\"].astype(str)\n",
    "\n",
    "topics.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiments\n",
    "Results file format from: http://www.rafaelglater.com/en/post/learn-how-to-use-trec_eval-to-evaluate-your-information-retrieval-system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyserini.search import SimpleSearcher\n",
    "\n",
    "#searcher = SimpleSearcher('G:/python/anserini/lucene-index.robust04.pos+docvectors+rawdocs')\n",
    "#searcher = SimpleSearcher('C:/msmarco-doc/lucene-index.msmarco-doc.pos+docvectors+rawdocs')\n",
    "#searcher = SimpleSearcher('C:/Users/Thijs-Jan-Luttikholt/Documents/Study/Master/Year 1/Information retrieval/Project/lucene-index.msmarco-doc.pos+docvectors+rawdocs/lucene-index.msmarco-doc.pos+docvectors+rawdocs')\n",
    "searcher = SimpleSearcher('C:/Users/Loes/Documents/M1/IR/data/lucene-index.msmarco-doc.pos+docvectors+rawdocs')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BM25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "searcher.set_bm25(0.9, 0.4)\n",
    "\n",
    "f = open(\"runs2/bm25.txt\", \"w\") \n",
    "for (topicid,question) in zip(topics[\"ID\"], topics[\"Question\"]):\n",
    "    hits = searcher.search(question)\n",
    "    for i in range(0, 10):\n",
    "        f.write(f'{topicid}\\tQ0\\t{hits[i].docid}\\t{i+1:2}\\t{hits[i].score:.5f}\\tSTANDARD\\n')   \n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BM25+RM3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "searcher.set_bm25(0.9, 0.4)\n",
    "searcher.set_rm3(10, 10, 0.5,rm3_output_query=True)\n",
    "\n",
    "f = open(\"runs2/bm25+rm3.txt\", \"w\") \n",
    "for (topicid,question) in zip(topics[\"ID\"], topics[\"Question\"]):\n",
    "    hits = searcher.search(question)\n",
    "    for i in range(0, 10):\n",
    "        f.write(f'{topicid}\\tQ0\\t{hits[i].docid}\\t{i+1:2}\\t{hits[i].score:.5f}\\tSTANDARD\\n')\n",
    "f.close()\n",
    "\n",
    "searcher.unset_rm3()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word2Vec QE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Loes\\Anaconda3b\\lib\\site-packages\\ipykernel_launcher.py:10: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    }
   ],
   "source": [
    "import gensim \n",
    "from gensim.models import Word2Vec\n",
    "import gensim.downloader as api\n",
    "import spacy\n",
    "from pyserini.analysis import Analyzer, get_lucene_analyzer\n",
    "\n",
    "#path = \"G:/data/glove.6B.300d.w2v.txt\"\n",
    "path = \"C:/Users/Loes/Documents/M1/IR/glove.6B.300d.w2v.txt\"\n",
    "model = gensim.models.KeyedVectors.load_word2vec_format(path, binary = False)\n",
    "word_vectors = model.wv\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "analyzer = Analyzer(get_lucene_analyzer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'do goldfish grow' expansions:\n",
      "    goldfish -> koi\n",
      "    grow -> growth\n",
      "\n",
      "\n",
      "'what is wifi vs bluetooth' expansions:\n",
      "    wifi -> wi-fi\n",
      "    vs -> vs.\n",
      "    bluetooth -> wifi\n",
      "\n",
      "\n",
      "'why did the us volunterilay enter ww1' expansions:\n",
      "    enter -> entry\n",
      "    ww1 -> ww2\n",
      "\n",
      "\n",
      "'definition declaratory judgment' expansions:\n",
      "    definition -> defined\n",
      "    declaratory -> injunctive\n",
      "    judgment -> judgement\n",
      "\n",
      "\n",
      "'right pelvic pain causes' expansions:\n",
      "    right -> left\n",
      "    pelvic -> abdominal\n",
      "    pain -> discomfort\n",
      "    causes -> disease\n",
      "\n",
      "\n",
      "'what are the social determinants of health' expansions:\n",
      "    social -> welfare\n",
      "    determinants -> predictors\n",
      "    health -> care\n",
      "\n",
      "\n",
      "'how is the weather in jamaica' expansions:\n",
      "    weather -> inclement\n",
      "    jamaica -> barbados\n",
      "\n",
      "\n",
      "'types of dysarthria from cerebral palsy' expansions:\n",
      "    types -> kinds\n",
      "    dysarthria -> ataxic\n",
      "    cerebral -> palsy\n",
      "    palsy -> cerebral\n",
      "\n",
      "\n",
      "'who is robert gray' expansions:\n",
      "    robert -> william\n",
      "    gray -> grey\n",
      "\n",
      "\n",
      "'what types of food can you cook sous vide' expansions:\n",
      "    types -> kinds\n",
      "    food -> foods\n",
      "    cook -> fry\n",
      "    sous -> clichy\n",
      "    vide -> sous\n",
      "\n",
      "\n",
      "'how long is life cycle of flea' expansions:\n",
      "    long -> short\n",
      "    life -> years\n",
      "    cycle -> beginning\n",
      "    flea -> fleas\n",
      "\n",
      "\n",
      "'what can contour plowing reduce' expansions:\n",
      "    contour -> contours\n",
      "    plowing -> ploughing\n",
      "    reduce -> increase\n",
      "\n",
      "\n",
      "'when was the salvation army founded' expansions:\n",
      "    salvation -> redemption\n",
      "    army -> military\n",
      "    founded -> established\n",
      "\n",
      "\n",
      "'what is a active margin' expansions:\n",
      "    active -> actively\n",
      "    margin -> percentage\n",
      "\n",
      "\n",
      "'difference between rn and bsn' expansions:\n",
      "    difference -> fact\n",
      "    rn -> clr\n",
      "    bsn -> simpanan\n",
      "\n",
      "\n",
      "'medicare's definition of mechanical ventilation' expansions:\n",
      "    definition -> defined\n",
      "    mechanical -> electrical\n",
      "    ventilation -> hvac\n",
      "\n",
      "\n",
      "'how to find the midsegment of a trapezoid' expansions:\n",
      "    find -> able\n",
      "    trapezoid -> trapezoidal\n",
      "\n",
      "\n",
      "'what is an aml surveillance analyst' expansions:\n",
      "    aml -> myeloid\n",
      "    surveillance -> monitoring\n",
      "    analyst -> lynch\n",
      "\n",
      "\n",
      "'what is the daily life of thai people' expansions:\n",
      "    daily -> newspaper\n",
      "    life -> years\n",
      "    thai -> thailand\n",
      "    people -> others\n",
      "\n",
      "\n",
      "'definition of a sigmet' expansions:\n",
      "    definition -> defined\n",
      "\n",
      "\n",
      "'cost of interior concrete flooring' expansions:\n",
      "    cost -> pay\n",
      "    interior -> ministry\n",
      "    concrete -> walls\n",
      "    flooring -> laminate\n",
      "\n",
      "\n",
      "'what is the most popular food in switzerland' expansions:\n",
      "    popular -> popularity\n",
      "    food -> foods\n",
      "    switzerland -> swiss\n",
      "\n",
      "\n",
      "'how are some sharks warm blooded' expansions:\n",
      "    sharks -> shark\n",
      "    warm -> cool\n",
      "    blooded -> cold-blooded\n",
      "\n",
      "\n",
      "'how long to hold bow in yoga' expansions:\n",
      "    long -> short\n",
      "    hold -> take\n",
      "    bow -> jhaw\n",
      "    yoga -> meditation\n",
      "\n",
      "\n",
      "'what is durable medical equipment consist of' expansions:\n",
      "    durable -> goods\n",
      "    medical -> hospital\n",
      "    equipment -> machinery\n",
      "    consist -> comprise\n",
      "\n",
      "\n",
      "'exons definition biology' expansions:\n",
      "    exons -> introns\n",
      "    definition -> defined\n",
      "    biology -> biochemistry\n",
      "\n",
      "\n",
      "'define visceral?' expansions:\n",
      "    define -> redefine\n",
      "\n",
      "\n",
      "'tracheids are part of _____.' expansions:\n",
      "    tracheids -> xerophytic\n",
      "\n",
      "\n",
      "'how many liberty ships were built in brunswick' expansions:\n",
      "    liberty -> freedom\n",
      "    ships -> vessels\n",
      "    built -> constructed\n",
      "    brunswick -> scotia\n",
      "\n",
      "\n",
      "'rsa definition key' expansions:\n",
      "    rsa -> aus\n",
      "    definition -> defined\n",
      "    key -> crucial\n",
      "\n",
      "\n",
      "'who formed the commonwealth of independent states' expansions:\n",
      "    formed -> formation\n",
      "    commonwealth -> polish-lithuanian\n",
      "    independent -> independence\n",
      "    states -> united\n",
      "\n",
      "\n",
      "'causes of left ventricular hypertrophy' expansions:\n",
      "    causes -> disease\n",
      "    left -> leaving\n",
      "    ventricular -> atrial\n",
      "    hypertrophy -> ventricular\n",
      "\n",
      "\n",
      "'lps laws definition' expansions:\n",
      "    lps -> 45s\n",
      "    laws -> regulations\n",
      "    definition -> defined\n",
      "\n",
      "\n",
      "'causes of military suicide' expansions:\n",
      "    causes -> disease\n",
      "    military -> army\n",
      "    suicide -> bombings\n",
      "\n",
      "\n",
      "'what is theraderm used for' expansions:\n",
      "\n",
      "\n",
      "'what is famvir prescribed for' expansions:\n",
      "    famvir -> valtrex\n",
      "    prescribed -> medication\n",
      "\n",
      "\n",
      "'anthropological definition of environment' expansions:\n",
      "    anthropological -> ethnological\n",
      "    definition -> defined\n",
      "    environment -> environmental\n",
      "\n",
      "\n",
      "'axon terminals or synaptic knob definition' expansions:\n",
      "    axon -> axonal\n",
      "    terminals -> ports\n",
      "    synaptic -> plasticity\n",
      "    knob -> knobs\n",
      "    definition -> defined\n",
      "\n",
      "\n",
      "'is cdg airport in main paris' expansions:\n",
      "    cdg -> -8.00\n",
      "    airport -> flights\n",
      "    main -> key\n",
      "    paris -> prohertrib\n",
      "\n",
      "\n",
      "'example of monotonic function' expansions:\n",
      "    example -> instance\n",
      "    monotonic -> real-valued\n",
      "    function -> i.e.\n",
      "\n",
      "\n",
      "'what is physical description of spruce' expansions:\n",
      "    physical -> mental\n",
      "    description -> describing\n",
      "    spruce -> fir\n",
      "\n",
      "\n",
      "'hydrogen is a liquid below what temperature' expansions:\n",
      "    hydrogen -> helium\n",
      "    liquid -> mixture\n",
      "    temperature -> humidity\n",
      "\n",
      "\n",
      "'difference between a mcdouble and a double cheeseburger' expansions:\n",
      "    difference -> fact\n",
      "    double -> triple\n",
      "    cheeseburger -> fries\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyserini.search import querybuilder as qb\n",
    "\n",
    "f = open(\"runs/word2vec.txt\", \"w\") \n",
    "for (topicid,question) in zip(topics[\"ID\"], topics[\"Question\"]):\n",
    "    # Build the query\n",
    "    builder = qb.get_boolean_query_builder()\n",
    "    should = qb.JBooleanClauseOccur['should'].value # should occur\n",
    "    print(\"'\"+question+\"' expansions:\")\n",
    "    for token in question.split(\" \"):\n",
    "        if len(analyzer.analyze(token))>0:\n",
    "            # add question token\n",
    "            builder.add(qb.get_boost_query(qb.get_term_query(token), 1),should)\n",
    "            \n",
    "            # word2vec expansion\n",
    "            if token in word_vectors.vocab and not token in nlp.Defaults.stop_words:\n",
    "                token_lemma = nlp(token)[0].lemma_\n",
    "                syns = model.most_similar(token)\n",
    "                synonyms = [syn for (syn,score) in syns if nlp(syn)[0].lemma_ != token_lemma][:1]\n",
    "                for synonym in synonyms:\n",
    "                    if len(analyzer.analyze(synonym))>0:\n",
    "                        # add query term\n",
    "                        builder.add(qb.get_boost_query(qb.get_term_query(token), 0.1),should)\n",
    "                        print(\"    \"+token+\" -> \"+synonym)\n",
    "            \n",
    "    question = builder.build()\n",
    "    print(\"\\n\")\n",
    "\n",
    "    hits = searcher.search(question)\n",
    "    for i in range(0, 10):\n",
    "        f.write(f'{topicid}\\tQ0\\t{hits[i].docid}\\t{i+1:2}\\t{hits[i].score:.5f}\\tSTANDARD\\n')\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wordnet QE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import wordnet as wn \n",
    "from nltk.tokenize import sent_tokenize, word_tokenize \n",
    "import warnings \n",
    "from nltk.corpus import words\n",
    "from operator import itemgetter\n",
    "from pyserini.search import querybuilder as qb\n",
    "from pyserini.analysis import Analyzer, get_lucene_analyzer\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package words to\n",
      "[nltk_data]     C:\\Users\\Loes\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('words')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The following function creates a set containing synonyms for each word in the input list.\n",
    "def add_synonyms(myList):\n",
    "    synonyms = []\n",
    "    for word in myList:\n",
    "        for syn in wn.synsets(word):\n",
    "            for l in syn.lemmas():\n",
    "                synonyms.append(l.name())\n",
    "    return sorted(set(synonyms))\n",
    "\n",
    "#The following function creates a set containing hypernyms for each word in the input list.\n",
    "def add_hypernyms(myList):\n",
    "    hypernyms = []\n",
    "    for word in myList:\n",
    "        for syn in wn.synsets(word):\n",
    "            for h in syn.hypernyms():\n",
    "                hypernyms.append(h.name().split('.')[0])\n",
    "    return sorted(set(hypernyms))\n",
    "\n",
    "#The following function creates a set containing hyponyms for each word in the input list.\n",
    "def add_hyponyms(myList):\n",
    "    hyponyms = []\n",
    "    for word in myList:\n",
    "        for syn in wn.synsets(word):\n",
    "            for h in syn.hyponyms():\n",
    "                hyponyms.append(h.name().split('.')[0])\n",
    "    return sorted(set(hyponyms))\n",
    "\n",
    "#The following function creates a set containing meronyms for each word in the input list.\n",
    "def add_meronyms(myList):\n",
    "    meronyms = []\n",
    "    for word in myList:\n",
    "        for syn in wn.synsets(word):\n",
    "            for m in syn.part_meronyms():\n",
    "                meronyms.append(m.name().split('.')[0])\n",
    "    return sorted(set(meronyms))\n",
    "\n",
    "#The following function creates a set containing holonyms for each word in the input list.\n",
    "def add_holonyms(myList):\n",
    "    holonyms = []\n",
    "    for word in myList:\n",
    "        for syn in wn.synsets(word):\n",
    "            for m in syn.part_holonyms():\n",
    "                holonyms.append(m.name().split('.')[0])\n",
    "    return sorted(set(holonyms))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['arise', 'develop']\n",
      "['acquire', 'get', 'arise']\n"
     ]
    }
   ],
   "source": [
    "#previous definition that gave different \n",
    "def best_sim(original, synonyms, max_len, min_sim):\n",
    "    syns_scores = []\n",
    "    orig_set = wn.synsets(original)[0]\n",
    "    set_type = orig_set.name().split('.')[1]\n",
    "    lscores = []\n",
    "    if original in synonyms:\n",
    "        synonyms.remove(original)\n",
    "    \n",
    "    for word in synonyms:\n",
    "        word_sets = wn.synsets(word)\n",
    "        word_set = None\n",
    "        for item in word_sets:\n",
    "            if item.name().split('.')[1] is set_type:\n",
    "                word_set = item\n",
    "                break\n",
    "        if word_set is None:\n",
    "            continue\n",
    "        score = orig_set.path_similarity(word_set) \n",
    "        if score is None:\n",
    "            score = 0\n",
    "        else:\n",
    "            lscores.append(score)\n",
    "    d = dict(zip(synonyms,lscores))\n",
    "    ds = dict(sorted(d.items(), key=lambda item: item[1], reverse=True))\n",
    "    ds2 = {k: v for k, v in ds.items() if v >= min_sim}\n",
    "    ds5 = (list(ds.keys()))[:max_len]\n",
    "    return ds5\n",
    "\n",
    "def filter_words(myList):\n",
    "    new_list = []\n",
    "    for item in myList:\n",
    "        if '_' in item:\n",
    "            new_list.append(item.replace(\"_\",\" \"))\n",
    "        else:\n",
    "            new_list.append(item)\n",
    "    return new_list\n",
    "\n",
    "best_syns = best_similars('grow', add_synonyms(['grow']), 3, 0.2)\n",
    "best_syns2 = best_sim2('grow', add_synonyms(['grow']), 3, 0.2)\n",
    "print(filter_words(best_syns))\n",
    "print(best_syns2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzer = Analyzer(get_lucene_analyzer())\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Only adding synonyms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'do goldfish grow' expansions:\n",
      "    grow -> produce\n",
      "    grow -> develop\n",
      "\n",
      "\n",
      "'what is wifi vs bluetooth' expansions:\n",
      "\n",
      "\n",
      "'why did the us volunterilay enter ww1' expansions:\n",
      "    enter -> infix\n",
      "\n",
      "\n",
      "'definition declaratory judgment' expansions:\n",
      "    declaratory -> declarative\n",
      "    declaratory -> asserting\n",
      "    judgment -> opinion\n",
      "\n",
      "\n",
      "'right pelvic pain causes' expansions:\n",
      "    pain -> hurting\n",
      "\n",
      "\n",
      "'what are the social determinants of health' expansions:\n",
      "    social -> sociable\n",
      "    social -> mixer\n",
      "    health -> wellness\n",
      "\n",
      "\n",
      "'how is the weather in jamaica' expansions:\n",
      "\n",
      "\n",
      "'types of dysarthria from cerebral palsy' expansions:\n",
      "    palsy -> paralysis\n",
      "\n",
      "\n",
      "'who is robert gray' expansions:\n",
      "    gray -> Gray\n",
      "    gray -> greyness\n",
      "\n",
      "\n",
      "'what types of food can you cook sous vide' expansions:\n",
      "    food -> nutrient\n",
      "    cook -> Cook\n",
      "\n",
      "\n",
      "'how long is life cycle of flea' expansions:\n",
      "    long -> hanker\n",
      "    long -> yearn\n",
      "    life -> aliveness\n",
      "    life -> animation\n",
      "\n",
      "\n",
      "'what can contour plowing reduce' expansions:\n",
      "    plowing -> ploughing\n",
      "    reduce -> foreshorten\n",
      "\n",
      "\n",
      "'when was the salvation army founded' expansions:\n",
      "    salvation -> redemption\n",
      "    army -> Army\n",
      "\n",
      "\n",
      "'what is a active margin' expansions:\n",
      "    margin -> perimeter\n",
      "\n",
      "\n",
      "'difference between rn and bsn' expansions:\n",
      "\n",
      "\n",
      "'medicare's definition of mechanical ventilation' expansions:\n",
      "\n",
      "\n",
      "'how to find the midsegment of a trapezoid' expansions:\n",
      "    find -> breakthrough\n",
      "\n",
      "\n",
      "'what is an aml surveillance analyst' expansions:\n",
      "\n",
      "\n",
      "'what is the daily life of thai people' expansions:\n",
      "    life -> aliveness\n",
      "    life -> animation\n",
      "    people -> masses\n",
      "\n",
      "\n",
      "'definition of a sigmet' expansions:\n",
      "\n",
      "\n",
      "'cost of interior concrete flooring' expansions:\n",
      "    cost -> toll\n",
      "    interior -> Interior\n",
      "    interior -> inside\n",
      "    flooring -> deck\n",
      "    flooring -> floor\n",
      "\n",
      "\n",
      "'what is the most popular food in switzerland' expansions:\n",
      "    food -> nutrient\n",
      "\n",
      "\n",
      "'how are some sharks warm blooded' expansions:\n",
      "    warm -> tender\n",
      "    blooded -> blood\n",
      "\n",
      "\n",
      "'how long to hold bow in yoga' expansions:\n",
      "    long -> hanker\n",
      "    long -> yearn\n",
      "    hold -> support\n",
      "    hold -> clutch\n",
      "    bow -> bowknot\n",
      "\n",
      "\n",
      "'what is durable medical equipment consist of' expansions:\n",
      "    durable -> lasting\n",
      "    durable -> long-lasting\n",
      "    durable -> long-lived\n",
      "    medical -> checkup\n",
      "    consist -> comprise\n",
      "\n",
      "\n",
      "'exons definition biology' expansions:\n",
      "\n",
      "\n",
      "'define visceral?' expansions:\n",
      "    define -> set\n",
      "    define -> delimitate\n",
      "\n",
      "\n",
      "'tracheids are part of _____.' expansions:\n",
      "\n",
      "\n",
      "'how many liberty ships were built in brunswick' expansions:\n",
      "    liberty -> autonomy\n",
      "    built -> establish\n",
      "    built -> build\n",
      "    built -> construct\n",
      "    brunswick -> Braunschweig\n",
      "    brunswick -> Brunswick\n",
      "\n",
      "\n",
      "'rsa definition key' expansions:\n",
      "    key -> Key\n",
      "\n",
      "\n",
      "'who formed the commonwealth of independent states' expansions:\n",
      "    formed -> spring\n",
      "    formed -> shape\n",
      "    formed -> form\n",
      "    commonwealth -> state\n",
      "    independent -> free-lance\n",
      "\n",
      "\n",
      "'causes of left ventricular hypertrophy' expansions:\n",
      "\n",
      "\n",
      "'lps laws definition' expansions:\n",
      "\n",
      "\n",
      "'causes of military suicide' expansions:\n",
      "    suicide -> self-destruction\n",
      "    suicide -> self-annihilation\n",
      "\n",
      "\n",
      "'what is theraderm used for' expansions:\n",
      "\n",
      "\n",
      "'what is famvir prescribed for' expansions:\n",
      "\n",
      "\n",
      "'anthropological definition of environment' expansions:\n",
      "    environment -> surroundings\n",
      "\n",
      "\n",
      "'axon terminals or synaptic knob definition' expansions:\n",
      "    axon -> axone\n",
      "\n",
      "\n",
      "'is cdg airport in main paris' expansions:\n",
      "    airport -> aerodrome\n",
      "    airport -> drome\n",
      "    airport -> airdrome\n",
      "    main -> briny\n",
      "\n",
      "\n",
      "'example of monotonic function' expansions:\n",
      "    monotonic -> monotone\n",
      "    function -> part\n",
      "\n",
      "\n",
      "'what is physical description of spruce' expansions:\n",
      "\n",
      "\n",
      "'hydrogen is a liquid below what temperature' expansions:\n",
      "    hydrogen -> H\n",
      "    liquid -> fluid\n",
      "\n",
      "\n",
      "'difference between a mcdouble and a double cheeseburger' expansions:\n",
      "    double -> two-baser\n",
      "    double -> two-bagger\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "f = open(\"runs/wordnet_synonyms.txt\", \"w\") \n",
    "for (topicid,question) in zip(topics[\"ID\"], topics[\"Question\"]):\n",
    "    # Build the query\n",
    "    builder = qb.get_boolean_query_builder()\n",
    "    should = qb.JBooleanClauseOccur['should'].value # should occur\n",
    "    print(\"'\"+question+\"' expansions:\")\n",
    "    for token in question.split(\" \"):\n",
    "        if len(analyzer.analyze(token))>0:\n",
    "            # add question token\n",
    "            builder.add(qb.get_boost_query(qb.get_term_query(token), 1),should)\n",
    "            \n",
    "            # wordnet expansion\n",
    "            if token not in nlp.Defaults.stop_words and token in words.words():\n",
    "                token_lemma = nlp(token)[0].lemma_\n",
    "                \n",
    "                wordnet_synonyms = add_synonyms([token])\n",
    "                synonyms = best_sim(token, wordnet_synonyms, 3, 0.2)\n",
    "                synonyms = filter_words(synonyms)\n",
    "                for synonym in synonyms:\n",
    "                    if len(analyzer.analyze(synonym))>0:\n",
    "                        # add query term\n",
    "                        builder.add(qb.get_boost_query(qb.get_term_query(synonym), 0.1),should)\n",
    "                        print(\"    \"+token+\" -> \"+synonym)\n",
    "            \n",
    "    question = builder.build()\n",
    "    print(\"\\n\")\n",
    "\n",
    "    hits = searcher.search(question)\n",
    "    for i in range(0, 10):\n",
    "        f.write(f'{topicid}\\tQ0\\t{hits[i].docid}\\t{i+1:2}\\t{hits[i].score:.5f}\\tSTANDARD\\n')\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Only adding hypernyms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "f = open(\"runs/wordnet_hypernyms.txt\", \"w\") \n",
    "for (topicid,question) in zip(topics[\"ID\"], topics[\"Question\"]):\n",
    "    # Build the query\n",
    "    builder = qb.get_boolean_query_builder()\n",
    "    should = qb.JBooleanClauseOccur['should'].value # should occur\n",
    "    print(\"'\"+question+\"' expansions:\")\n",
    "    for token in question.split(\" \"):\n",
    "        if len(analyzer.analyze(token))>0:\n",
    "            # add question token\n",
    "            builder.add(qb.get_boost_query(qb.get_term_query(token), 1),should)\n",
    "            \n",
    "            # wordnet expansion\n",
    "            if token not in nlp.Defaults.stop_words and token in words.words():\n",
    "                token_lemma = nlp(token)[0].lemma_\n",
    "                \n",
    "                wordnet_hypernyms = add_hypernyms([token])\n",
    "                hypernyms = best_sim(token, wordnet_hypernyms, 3, 0.2)\n",
    "                hypernyms = filter_words(hypernyms)\n",
    "                for hypernym in hypernyms:\n",
    "                    if len(analyzer.analyze(hypernym))>0:\n",
    "                        # add query term\n",
    "                        builder.add(qb.get_boost_query(qb.get_term_query(hypernym), 0.1),should)\n",
    "                        print(\"    \"+token+\" -> \"+hypernym)\n",
    "            \n",
    "    question = builder.build()\n",
    "    print(\"\\n\")\n",
    "\n",
    "    hits = searcher.search(question)\n",
    "    for i in range(0, 10):\n",
    "        f.write(f'{topicid}\\tQ0\\t{hits[i].docid}\\t{i+1:2}\\t{hits[i].score:.5f}\\tSTANDARD\\n')\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Only adding hyponyms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'do goldfish grow' expansions:\n",
      "    grow -> rise\n",
      "    grow -> ripen\n",
      "    grow -> bald\n",
      "\n",
      "\n",
      "'what is wifi vs bluetooth' expansions:\n",
      "\n",
      "\n",
      "'why did the us volunterilay enter ww1' expansions:\n",
      "    enter -> transplant\n",
      "    enter -> ascend\n",
      "\n",
      "\n",
      "'definition declaratory judgment' expansions:\n",
      "    judgment -> opinion\n",
      "\n",
      "\n",
      "'right pelvic pain causes' expansions:\n",
      "    right -> prerogative\n",
      "    right -> access\n",
      "    pain -> smart\n",
      "    pain -> proctalgia\n",
      "\n",
      "\n",
      "'what are the social determinants of health' expansions:\n",
      "\n",
      "\n",
      "'how is the weather in jamaica' expansions:\n",
      "    weather -> elements\n",
      "\n",
      "\n",
      "'types of dysarthria from cerebral palsy' expansions:\n",
      "    palsy -> paresis\n",
      "    palsy -> cystoplegia\n",
      "    palsy -> quadriplegia\n",
      "\n",
      "\n",
      "'who is robert gray' expansions:\n",
      "    gray -> dapple-grey\n",
      "    gray -> iron-grey\n",
      "\n",
      "\n",
      "'what types of food can you cook sous vide' expansions:\n",
      "    food -> yogurt\n",
      "    food -> comestible\n",
      "    food -> beverage\n",
      "    cook -> preserver\n",
      "    cook -> chef\n",
      "\n",
      "\n",
      "'how long is life cycle of flea' expansions:\n",
      "    long -> ache\n",
      "    life -> survival\n",
      "\n",
      "\n",
      "'what can contour plowing reduce' expansions:\n",
      "    reduce -> miniaturize\n",
      "    reduce -> shorten\n",
      "\n",
      "\n",
      "'when was the salvation army founded' expansions:\n",
      "\n",
      "\n",
      "'what is a active margin' expansions:\n",
      "\n",
      "\n",
      "'difference between rn and bsn' expansions:\n",
      "    difference -> gap\n",
      "    difference -> inequality\n",
      "    difference -> discrepancy\n",
      "\n",
      "\n",
      "'medicare's definition of mechanical ventilation' expansions:\n",
      "\n",
      "\n",
      "'how to find the midsegment of a trapezoid' expansions:\n",
      "    find -> breakthrough\n",
      "\n",
      "\n",
      "'what is an aml surveillance analyst' expansions:\n",
      "    surveillance -> stakeout\n",
      "    analyst -> assayer\n",
      "\n",
      "\n",
      "'what is the daily life of thai people' expansions:\n",
      "    life -> survival\n",
      "    people -> homebound\n",
      "    people -> tradespeople\n",
      "    people -> uninitiate\n",
      "\n",
      "\n",
      "'definition of a sigmet' expansions:\n",
      "\n",
      "\n",
      "'cost of interior concrete flooring' expansions:\n",
      "    cost -> portage\n",
      "    interior -> midst\n",
      "    interior -> penetralia\n",
      "    concrete -> cement\n",
      "    flooring -> parquet\n",
      "\n",
      "\n",
      "'what is the most popular food in switzerland' expansions:\n",
      "    food -> yogurt\n",
      "    food -> comestible\n",
      "    food -> beverage\n",
      "\n",
      "\n",
      "'how are some sharks warm blooded' expansions:\n",
      "\n",
      "\n",
      "'how long to hold bow in yoga' expansions:\n",
      "    long -> ache\n",
      "    hold -> embrace\n",
      "\n",
      "\n",
      "'what is durable medical equipment consist of' expansions:\n",
      "    equipment -> recorder\n",
      "\n",
      "\n",
      "'exons definition biology' expansions:\n",
      "    biology -> radiobiology\n",
      "    biology -> sociobiology\n",
      "    biology -> microbiology\n",
      "\n",
      "\n",
      "'define visceral?' expansions:\n",
      "    define -> determine\n",
      "    define -> redefine\n",
      "\n",
      "\n",
      "'tracheids are part of _____.' expansions:\n",
      "\n",
      "\n",
      "'how many liberty ships were built in brunswick' expansions:\n",
      "    liberty -> discretion\n",
      "    liberty -> self-government\n",
      "    built -> wattle\n",
      "    built -> dry-wall\n",
      "    built -> corduroy\n",
      "\n",
      "\n",
      "'rsa definition key' expansions:\n",
      "    key -> latchkey\n",
      "    key -> passkey\n",
      "\n",
      "\n",
      "'who formed the commonwealth of independent states' expansions:\n",
      "    formed -> twist\n",
      "    formed -> syndicate\n",
      "\n",
      "\n",
      "'causes of left ventricular hypertrophy' expansions:\n",
      "    hypertrophy -> adenomegaly\n",
      "    hypertrophy -> splenomegaly\n",
      "\n",
      "\n",
      "'lps laws definition' expansions:\n",
      "\n",
      "\n",
      "'causes of military suicide' expansions:\n",
      "    suicide -> harakiri\n",
      "    suicide -> suttee\n",
      "\n",
      "\n",
      "'what is theraderm used for' expansions:\n",
      "\n",
      "\n",
      "'what is famvir prescribed for' expansions:\n",
      "\n",
      "\n",
      "'anthropological definition of environment' expansions:\n",
      "    environment -> ambiance\n",
      "    environment -> sphere\n",
      "    environment -> ecology\n",
      "\n",
      "\n",
      "'axon terminals or synaptic knob definition' expansions:\n",
      "    knob -> knobble\n",
      "\n",
      "\n",
      "'is cdg airport in main paris' expansions:\n",
      "    airport -> heliport\n",
      "\n",
      "\n",
      "'example of monotonic function' expansions:\n",
      "    example -> pattern\n",
      "    example -> specimen\n",
      "    example -> sample\n",
      "    function -> operator\n",
      "\n",
      "\n",
      "'what is physical description of spruce' expansions:\n",
      "    description -> specification\n",
      "    description -> characterization\n",
      "\n",
      "\n",
      "'hydrogen is a liquid below what temperature' expansions:\n",
      "    hydrogen -> tritium\n",
      "    liquid -> beverage\n",
      "    liquid -> ink\n",
      "    temperature -> hotness\n",
      "\n",
      "\n",
      "'difference between a mcdouble and a double cheeseburger' expansions:\n",
      "    difference -> gap\n",
      "    difference -> inequality\n",
      "    difference -> discrepancy\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "f = open(\"runs/wordnet_hyponyms.txt\", \"w\") \n",
    "for (topicid,question) in zip(topics[\"ID\"], topics[\"Question\"]):\n",
    "    # Build the query\n",
    "    builder = qb.get_boolean_query_builder()\n",
    "    should = qb.JBooleanClauseOccur['should'].value # should occur\n",
    "    print(\"'\"+question+\"' expansions:\")\n",
    "    for token in question.split(\" \"):\n",
    "        if len(analyzer.analyze(token))>0:\n",
    "            # add question token\n",
    "            builder.add(qb.get_boost_query(qb.get_term_query(token), 1),should)\n",
    "            \n",
    "            # wordnet expansion\n",
    "            if token not in nlp.Defaults.stop_words and token in words.words():\n",
    "                token_lemma = nlp(token)[0].lemma_\n",
    "                \n",
    "                wordnet_hyponyms = add_hyponyms([token])\n",
    "                hyponyms = best_sim(token, wordnet_hyponyms, 3, 0.2)\n",
    "                hyponyms = filter_words(hyponyms)\n",
    "                for hyponym in hyponyms:\n",
    "                    if len(analyzer.analyze(hyponym))>0:\n",
    "                        # add query term\n",
    "                        builder.add(qb.get_boost_query(qb.get_term_query(hyponym), 0.1),should)\n",
    "                        print(\"    \"+token+\" -> \"+hyponym)\n",
    "            \n",
    "    question = builder.build()\n",
    "    print(\"\\n\")\n",
    "\n",
    "    hits = searcher.search(question)\n",
    "    for i in range(0, 10):\n",
    "        f.write(f'{topicid}\\tQ0\\t{hits[i].docid}\\t{i+1:2}\\t{hits[i].score:.5f}\\tSTANDARD\\n')\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Only adding meronyms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'do goldfish grow' expansions:\n",
      "\n",
      "\n",
      "'what is wifi vs bluetooth' expansions:\n",
      "\n",
      "\n",
      "'why did the us volunterilay enter ww1' expansions:\n",
      "\n",
      "\n",
      "'definition declaratory judgment' expansions:\n",
      "\n",
      "\n",
      "'right pelvic pain causes' expansions:\n",
      "\n",
      "\n",
      "'what are the social determinants of health' expansions:\n",
      "\n",
      "\n",
      "'how is the weather in jamaica' expansions:\n",
      "\n",
      "\n",
      "'types of dysarthria from cerebral palsy' expansions:\n",
      "\n",
      "\n",
      "'who is robert gray' expansions:\n",
      "\n",
      "\n",
      "'what types of food can you cook sous vide' expansions:\n",
      "\n",
      "\n",
      "'how long is life cycle of flea' expansions:\n",
      "    life -> death\n",
      "    life -> age\n",
      "    cycle -> sprocket\n",
      "    cycle -> chain\n",
      "    cycle -> phase\n",
      "\n",
      "\n",
      "'what can contour plowing reduce' expansions:\n",
      "\n",
      "\n",
      "'when was the salvation army founded' expansions:\n",
      "\n",
      "\n",
      "'what is a active margin' expansions:\n",
      "\n",
      "\n",
      "'difference between rn and bsn' expansions:\n",
      "\n",
      "\n",
      "'medicare's definition of mechanical ventilation' expansions:\n",
      "\n",
      "\n",
      "'how to find the midsegment of a trapezoid' expansions:\n",
      "\n",
      "\n",
      "'what is an aml surveillance analyst' expansions:\n",
      "\n",
      "\n",
      "'what is the daily life of thai people' expansions:\n",
      "    life -> death\n",
      "    life -> age\n",
      "\n",
      "\n",
      "'definition of a sigmet' expansions:\n",
      "\n",
      "\n",
      "'cost of interior concrete flooring' expansions:\n",
      "\n",
      "\n",
      "'what is the most popular food in switzerland' expansions:\n",
      "\n",
      "\n",
      "'how are some sharks warm blooded' expansions:\n",
      "\n",
      "\n",
      "'how long to hold bow in yoga' expansions:\n",
      "    bow -> bowstring\n",
      "\n",
      "\n",
      "'what is durable medical equipment consist of' expansions:\n",
      "\n",
      "\n",
      "'exons definition biology' expansions:\n",
      "\n",
      "\n",
      "'define visceral?' expansions:\n",
      "\n",
      "\n",
      "'tracheids are part of _____.' expansions:\n",
      "\n",
      "\n",
      "'how many liberty ships were built in brunswick' expansions:\n",
      "\n",
      "\n",
      "'rsa definition key' expansions:\n",
      "\n",
      "\n",
      "'who formed the commonwealth of independent states' expansions:\n",
      "\n",
      "\n",
      "'causes of left ventricular hypertrophy' expansions:\n",
      "\n",
      "\n",
      "'lps laws definition' expansions:\n",
      "\n",
      "\n",
      "'causes of military suicide' expansions:\n",
      "\n",
      "\n",
      "'what is theraderm used for' expansions:\n",
      "\n",
      "\n",
      "'what is famvir prescribed for' expansions:\n",
      "\n",
      "\n",
      "'anthropological definition of environment' expansions:\n",
      "\n",
      "\n",
      "'axon terminals or synaptic knob definition' expansions:\n",
      "\n",
      "\n",
      "'is cdg airport in main paris' expansions:\n",
      "    airport -> airdock\n",
      "    main -> offing\n",
      "\n",
      "\n",
      "'example of monotonic function' expansions:\n",
      "\n",
      "\n",
      "'what is physical description of spruce' expansions:\n",
      "\n",
      "\n",
      "'hydrogen is a liquid below what temperature' expansions:\n",
      "\n",
      "\n",
      "'difference between a mcdouble and a double cheeseburger' expansions:\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "f = open(\"runs/wordnet_meronyms.txt\", \"w\") \n",
    "for (topicid,question) in zip(topics[\"ID\"], topics[\"Question\"]):\n",
    "    # Build the query\n",
    "    builder = qb.get_boolean_query_builder()\n",
    "    should = qb.JBooleanClauseOccur['should'].value # should occur\n",
    "    print(\"'\"+question+\"' expansions:\")\n",
    "    for token in question.split(\" \"):\n",
    "        if len(analyzer.analyze(token))>0:\n",
    "            # add question token\n",
    "            builder.add(qb.get_boost_query(qb.get_term_query(token), 1),should)\n",
    "            \n",
    "            # wordnet expansion\n",
    "            if token not in nlp.Defaults.stop_words and token in words.words():\n",
    "                token_lemma = nlp(token)[0].lemma_\n",
    "                \n",
    "                wordnet_meronyms = add_meronyms([token])\n",
    "                meronyms = best_sim(token, wordnet_meronyms, 3, 0.1)\n",
    "                meronyms = filter_words(meronyms)\n",
    "                for meronym in meronyms:\n",
    "                    if len(analyzer.analyze(meronym))>0:\n",
    "                        # add query term\n",
    "                        builder.add(qb.get_boost_query(qb.get_term_query(meronym), 0.1),should)\n",
    "                        print(\"    \"+token+\" -> \"+meronym)\n",
    "            \n",
    "    question = builder.build()\n",
    "    print(\"\\n\")\n",
    "\n",
    "    hits = searcher.search(question)\n",
    "    for i in range(0, 10):\n",
    "        f.write(f'{topicid}\\tQ0\\t{hits[i].docid}\\t{i+1:2}\\t{hits[i].score:.5f}\\tSTANDARD\\n')\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Only adding holonyms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'do goldfish grow' expansions:\n",
      "\n",
      "\n",
      "'what is wifi vs bluetooth' expansions:\n",
      "\n",
      "\n",
      "'why did the us volunterilay enter ww1' expansions:\n",
      "\n",
      "\n",
      "'definition declaratory judgment' expansions:\n",
      "\n",
      "\n",
      "'right pelvic pain causes' expansions:\n",
      "\n",
      "\n",
      "'what are the social determinants of health' expansions:\n",
      "\n",
      "\n",
      "'how is the weather in jamaica' expansions:\n",
      "\n",
      "\n",
      "'types of dysarthria from cerebral palsy' expansions:\n",
      "\n",
      "\n",
      "'who is robert gray' expansions:\n",
      "\n",
      "\n",
      "'what types of food can you cook sous vide' expansions:\n",
      "\n",
      "\n",
      "'how long is life cycle of flea' expansions:\n",
      "    cycle -> kilohertz\n",
      "\n",
      "\n",
      "'what can contour plowing reduce' expansions:\n",
      "\n",
      "\n",
      "'when was the salvation army founded' expansions:\n",
      "\n",
      "\n",
      "'what is a active margin' expansions:\n",
      "\n",
      "\n",
      "'difference between rn and bsn' expansions:\n",
      "\n",
      "\n",
      "'medicare's definition of mechanical ventilation' expansions:\n",
      "\n",
      "\n",
      "'how to find the midsegment of a trapezoid' expansions:\n",
      "\n",
      "\n",
      "'what is an aml surveillance analyst' expansions:\n",
      "\n",
      "\n",
      "'what is the daily life of thai people' expansions:\n",
      "\n",
      "\n",
      "'definition of a sigmet' expansions:\n",
      "\n",
      "\n",
      "'cost of interior concrete flooring' expansions:\n",
      "    flooring -> hallway\n",
      "    flooring -> room\n",
      "\n",
      "\n",
      "'what is the most popular food in switzerland' expansions:\n",
      "\n",
      "\n",
      "'how are some sharks warm blooded' expansions:\n",
      "\n",
      "\n",
      "'how long to hold bow in yoga' expansions:\n",
      "    hold -> racket\n",
      "\n",
      "\n",
      "'what is durable medical equipment consist of' expansions:\n",
      "\n",
      "\n",
      "'exons definition biology' expansions:\n",
      "\n",
      "\n",
      "'define visceral?' expansions:\n",
      "\n",
      "\n",
      "'tracheids are part of _____.' expansions:\n",
      "\n",
      "\n",
      "'how many liberty ships were built in brunswick' expansions:\n",
      "    brunswick -> germany\n",
      "    brunswick -> maine\n",
      "\n",
      "\n",
      "'rsa definition key' expansions:\n",
      "\n",
      "\n",
      "'who formed the commonwealth of independent states' expansions:\n",
      "\n",
      "\n",
      "'causes of left ventricular hypertrophy' expansions:\n",
      "    left -> outfield\n",
      "\n",
      "\n",
      "'lps laws definition' expansions:\n",
      "\n",
      "\n",
      "'causes of military suicide' expansions:\n",
      "\n",
      "\n",
      "'what is theraderm used for' expansions:\n",
      "\n",
      "\n",
      "'what is famvir prescribed for' expansions:\n",
      "\n",
      "\n",
      "'anthropological definition of environment' expansions:\n",
      "\n",
      "\n",
      "'axon terminals or synaptic knob definition' expansions:\n",
      "    knob -> hilt\n",
      "\n",
      "\n",
      "'is cdg airport in main paris' expansions:\n",
      "    main -> hydrosphere\n",
      "\n",
      "\n",
      "'example of monotonic function' expansions:\n",
      "    function -> program\n",
      "\n",
      "\n",
      "'what is physical description of spruce' expansions:\n",
      "\n",
      "\n",
      "'hydrogen is a liquid below what temperature' expansions:\n",
      "\n",
      "\n",
      "'difference between a mcdouble and a double cheeseburger' expansions:\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "f = open(\"runs/wordnet_holonyms.txt\", \"w\") \n",
    "for (topicid,question) in zip(topics[\"ID\"], topics[\"Question\"]):\n",
    "    # Build the query\n",
    "    builder = qb.get_boolean_query_builder()\n",
    "    should = qb.JBooleanClauseOccur['should'].value # should occur\n",
    "    print(\"'\"+question+\"' expansions:\")\n",
    "    for token in question.split(\" \"):\n",
    "        if len(analyzer.analyze(token))>0:\n",
    "            # add question token\n",
    "            builder.add(qb.get_boost_query(qb.get_term_query(token), 1),should)\n",
    "            \n",
    "            # wordnet expansion\n",
    "            if token not in nlp.Defaults.stop_words and token in words.words():\n",
    "                token_lemma = nlp(token)[0].lemma_\n",
    "                \n",
    "                wordnet_holonyms = add_holonyms([token])\n",
    "                holonyms = best_sim(token, wordnet_holonyms, 3, 0.1)\n",
    "                holonyms = filter_words(holonyms)\n",
    "                for holonym in holonyms:\n",
    "                    if len(analyzer.analyze(holonym))>0:\n",
    "                        # add query term\n",
    "                        builder.add(qb.get_boost_query(qb.get_term_query(holonym), 0.1),should)\n",
    "                        print(\"    \"+token+\" -> \"+holonym)\n",
    "            \n",
    "    question = builder.build()\n",
    "    print(\"\\n\")\n",
    "\n",
    "    hits = searcher.search(question)\n",
    "    for i in range(0, 10):\n",
    "        f.write(f'{topicid}\\tQ0\\t{hits[i].docid}\\t{i+1:2}\\t{hits[i].score:.5f}\\tSTANDARD\\n')\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating files for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "syn3\n"
     ]
    }
   ],
   "source": [
    "def add_xnv(x,n,v):\n",
    "    wstr = \"runs2/wordnet_\" + x + str(n) + \".txt\"    \n",
    "    f = open(wstr, \"w\") \n",
    "    for (topicid,question) in zip(topics[\"ID\"], topics[\"Question\"]):\n",
    "        # Build the query\n",
    "        builder = qb.get_boolean_query_builder()\n",
    "        should = qb.JBooleanClauseOccur['should'].value # should occur\n",
    "        #print(question)\n",
    "        for token in question.split(\" \"):\n",
    "            if len(analyzer.analyze(token))>0:\n",
    "                # add question token\n",
    "                builder.add(qb.get_boost_query(qb.get_term_query(token), 1),should)\n",
    "\n",
    "                # wordnet expansion\n",
    "                if token not in nlp.Defaults.stop_words and token in words.words():\n",
    "                    token_lemma = nlp(token)[0].lemma_\n",
    "\n",
    "                    if x is \"synonyms\":\n",
    "                        wordnet_words = add_synonyms([token])\n",
    "                    elif x is \"hypernyms\":\n",
    "                        wordnet_words = add_hypernyms([token])\n",
    "                    elif x is \"hyponyms\":\n",
    "                        wordnet_words = add_hyponyms([token])\n",
    "                    elif x is \"meronyms\":\n",
    "                        wordnet_words = add_meronyms([token])\n",
    "                    elif x is \"holonyms\":\n",
    "                        wordnet_words = add_holonyms([token])\n",
    "                    else:\n",
    "                        print(\"input x is incorrect, should be synonyms/hypernyms/hyponyms/meronyms/holonyms\")\n",
    "                     \n",
    "                    #print(wordnet_words)\n",
    "                    if not wordnet_words:\n",
    "                        #print(\"empty\")\n",
    "                        continue\n",
    "                    ww = best_sim2(token, wordnet_words, n, v)\n",
    "                    ww = filter_words2(ww)\n",
    "                    for w in ww:\n",
    "                        if len(analyzer.analyze(w))>0:\n",
    "                            # add query term\n",
    "                            builder.add(qb.get_boost_query(qb.get_term_query(w), 0.1),should) #Can adapt the weight here\n",
    "                            #print(\"    \"+token+\" -> \"+w)\n",
    "\n",
    "        question = builder.build()\n",
    "        #print(\"\\n\")\n",
    "\n",
    "        hits = searcher.search(question)\n",
    "        for i in range(0, 10):\n",
    "            f.write(f'{topicid}\\tQ0\\t{hits[i].docid}\\t{i+1:2}\\t{hits[i].score:.5f}\\tSTANDARD\\n')\n",
    "    f.close()\n",
    "\n",
    "tests = [1,2,3]\n",
    "for i in tests:\n",
    "    add_xnv(\"synonyms\",i,0)\n",
    "    add_xnv(\"hypernyms\",i,0)\n",
    "    add_xnv(\"hyponyms\",i,0)\n",
    "    add_xnv(\"meronyms\",i,0)\n",
    "    add_xnv(\"holonyms\",i,0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_comb(x):\n",
    "    wstr = \"runs2/wordnet_\" + x + \".txt\"    \n",
    "    f = open(wstr, \"w\") \n",
    "    zipp = zip(topics[\"ID\"], topics[\"Question\"])\n",
    "    for (topicid,question) in zipp:\n",
    "        # Build the query\n",
    "        builder = qb.get_boolean_query_builder()\n",
    "        should = qb.JBooleanClauseOccur['should'].value # should occur\n",
    "        #print(\"'\"+question+\"' expansions:\")\n",
    "        for token in question.split(\" \"):\n",
    "            if len(analyzer.analyze(token))>0:\n",
    "                # add question token\n",
    "                builder.add(qb.get_boost_query(qb.get_term_query(token), 1),should)\n",
    "\n",
    "                # wordnet expansion\n",
    "                if token not in nlp.Defaults.stop_words and token in words.words():\n",
    "                    token_lemma = nlp(token)[0].lemma_\n",
    "                    ww = []    \n",
    "                    if x == \"hyper+hypo\":\n",
    "                        wordnet_words = add_hypernyms([token])\n",
    "                        wordnet_words.extend(add_hyponyms([token]))\n",
    "                        if not wordnet_words:\n",
    "                            continue\n",
    "                        ww = best_sim2(token, wordnet_words, 1, 0)\n",
    "                        ww = filter_words2(ww)\n",
    "                    elif x == \"mero+holo\":\n",
    "                        wordnet_words = add_meronyms([token])\n",
    "                        wordnet_words.extend(add_holonyms([token]))\n",
    "                        if not wordnet_words:\n",
    "                            continue\n",
    "                        ww = best_sim2(token, wordnet_words, 1, 0)\n",
    "                        ww = filter_words2(ww)\n",
    "                    elif x == \"syn+hyper+hypo\":\n",
    "                        wordnet_words = add_synonyms([token])\n",
    "                        wordnet_words.extend(add_hypernyms([token]))\n",
    "                        wordnet_words.extend(add_hyponyms([token]))\n",
    "                        if not wordnet_words:\n",
    "                            continue\n",
    "                        ww = best_sim2(token, wordnet_words, 1, 0)\n",
    "                        ww = filter_words2(ww)\n",
    "                    elif x == \"syn+mero+holo\":\n",
    "                        wordnet_words = add_synonyms([token])\n",
    "                        wordnet_words.extend(add_meronyms([token]))\n",
    "                        wordnet_words.extend(add_holonyms([token]))\n",
    "                        if not wordnet_words:\n",
    "                            continue\n",
    "                        ww = best_sim2(token, wordnet_words, 1, 0)\n",
    "                        ww = filter_words2(ww)\n",
    "                    elif x == \"all\":\n",
    "                        wordnet_words = add_synonyms([token])\n",
    "                        wordnet_words.extend(add_hypernyms([token]))\n",
    "                        wordnet_words.extend(add_hyponyms([token]))\n",
    "                        wordnet_words.extend(add_meronyms([token]))\n",
    "                        wordnet_words.extend(add_holonyms([token]))\n",
    "                        if not wordnet_words:\n",
    "                            continue\n",
    "                        ww = best_sim2(token, wordnet_words, 1, 0)\n",
    "                        ww = filter_words2(ww)\n",
    "                    else:\n",
    "                        print(\"input x is incorrect, should be synonyms/hypernyms/hyponyms/meronyms/holonyms\")\n",
    "                         \n",
    "                    for w in ww:\n",
    "                        if len(analyzer.analyze(w))>0:\n",
    "                            # add query term\n",
    "                            builder.add(qb.get_boost_query(qb.get_term_query(w), 0.1),should)\n",
    "                            #print(\"    \"+token+\" -> \"+w)\n",
    "\n",
    "        question = builder.build()\n",
    "        #print(\"\\n\")\n",
    "\n",
    "        hits = searcher.search(question)\n",
    "        for i in range(0, 10):\n",
    "            f.write(f'{topicid}\\tQ0\\t{hits[i].docid}\\t{i+1:2}\\t{hits[i].score:.5f}\\tSTANDARD\\n')\n",
    "    f.close()\n",
    "    \n",
    "\n",
    "add_comb(\"hyper+hypo\")\n",
    "add_comb(\"mero+holo\")\n",
    "add_comb(\"syn+hyper+hypo\")\n",
    "add_comb(\"syn+mero+holo\")\n",
    "add_comb(\"all\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
